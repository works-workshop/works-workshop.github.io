---
title: Keynote
icon: fa-chalkboard-teacher
order: 3
hide: false
---

<div id="keynote">
    <div id="title">
        <img src="/assets/images/carole-goble.jpg" alt="Carole Goble" style="max-width: 15em; border-radius: 0.5em"/>
        <h1>FAIR Computational Workflows</h1>
        <h3>Carole Goble, Dept of Computer Science, The University of Manchester, UK / ELIXIR-UK</h3>
    </div>

    <div id="abstract">
        <p style="font-size: 0.9em; line-height: 1.3em; margin-bottom: 1em">
            The FAIR principles (Findable, Accessible, Interoperable, Reusable) [1] have laid a foundation for sharing
            and publishing digital assets, starting with data and now extending to all digital objects including
            software [2].
            The use of computational workflows has accelerated in the past few years driven by the need for repetitive
            and scalable data processing, access to and exchange of processing know-how, and the desire for more
            reproducible (or at least transparent) and quality assured processing methods [3]. COVID-19 pandemic has
            highlighted the value of workflows [4]. Over 290 workflow systems are <a
                href="https://s.apache.org/existing-workflow-systems" target="_blank">currently available</a>, although
            a much
            smaller number are widely adopted [5].
            As first class, publishable research objects, it seems natural to apply FAIR principles to workflows [6].
            The FAIR data principles themselves originate from a desire to support automated data processing, by
            emphasizing machine accessibility of data and metadata. As workflows have a dual role as software and
            explicit method description, their FAIR properties draw from both data and software principles for
            descriptive metadata, software metrics, and versioning. However, workflows create unique challenges such as
            representing a complex lifecycle from specification to execution via a workflow system, through to the data
            created at the completion of the workflow. As workflows are chiefly concerned with the processing and
            creation of data they have an important role to play in ensuring and supporting data FAIRification.
        </p>
        <p style="font-size: 0.9em; line-height: 1.3em; margin-bottom: 1em">
            The work on defining and improving the FAIRness of workflows has already started. A whole ecosystem of
            tools, guidelines and best practices are under development to reduce the time needed to adapt, reuse and
            extend existing scientific workflows. For example, a fundamental tenet of FAIR is the universal availability
            of machine processable metadata. The <a href="https://www.eosc-life.eu/" target="_blank">European EOSC-Life
            Cluster</a> has developed a metadata framework for FAIR workflows based on <a
                href="https://bioschemas.org/profiles/ComputationalWorkflow/1.0-RELEASE/" target="_blank">schema.org</a>,
            <a href="https://www.researchobject.org/ro-crate/" target="_blank">RO-Crate</a> [7] and <a
                href="https://www.commonwl.org/" target="_blank">Common Workflow Language (CWL)</a> [8], and uses the
            <a href="https://ga4gh.github.io/tool-registry-service-schemas/" target="_blank">GA4GH TRS API</a> for a
            standardised communication protocol to support Accessibility. It has developed and runs the <a
                href="https://workflowhub.eu/" target="_blank">WorkflowHub</a> registry which uses both the framework
            and the protocol to support workflow Findability. EOSC-Life have made great efforts to on-board community
            workflow platforms such as <a href="https://galaxyproject.org/" target="_blank">Galaxy</a>, <a
                href="https://snakemake.readthedocs.io/en/stable/" target="_blank">snakemake</a>, <a
                href="https://www.nextflow.io/" target="_blank">nextflow</a> and CWL to carry and use FAIR metadata for
            discovery and reuse. As FAIR software needs to be usable and not just reusable, EOSC-Life has also developed
            services for, e.g. workflow testing
            (<a href="https://crs4.github.io/life_monitor/" target="_blank">LifeMonitor</a>), execution and
            benchmarking.
        </p>
        <p style="font-size: 0.9em; line-height: 1.3em; margin-bottom: 1em">
            The Interoperability principle is the hardest to unpack for both data and software. For workflows,
            interoperability follows two threads: (i) supporting workflow system interoperability through workflow
            descriptions independent of the underlying system (e.g. CWL and
            <a href="https://openwdl.org/" target="_blank">WDL</a>) and (ii) workflow component
            composability. Workflows are ideally composed of modular building blocks and these and the workflows
            themselves are expected to be reused, refactored, recycled and remixed. Thus, FAIR applies "all the way
            down": at the specification and execution level, and for the whole workflow and each of its components.
            Composability also relates to reuse – that is, adapting [2], a workflow or its component “can be understood,
            modified, built upon or incorporated into other workflow”. Reuse challenges also include being able to
            capture and then move workflow components, dependencies, and application environments in such a way as not
            to affect the resulting execution of the workflow. Interoperability and Reusability present important
            obligations on software developers to ensure that tools and datasets are workflow ready data with clean I/O
            programmatic interfaces, no usage restrictions, use of community data standards, and that they are simple to
            install and designed for portability. Workflow developers can be both <i>data-FAIR</i>, by using and making
            identifiers, licensing data outputs, tracking data provenance and so on, and <i>workflow-FAIR</i> by
            managing versions, providing test data, and sharing libraries of composable and reusable workflow “blocks”
            [9]. Communities are working on reviewing, validating and certifying canonical workflows.
        </p>
        <p style="font-size: 0.9em; line-height: 1.3em; margin-bottom: 1em">
            While there are emerging tools for addressing different aspects of FAIR workflows, many challenges remain
            for describing, annotating, and exposing scientific workflows so that they can be found, understood and
            reused by other scientists. Further work is required to understand use cases for reuse and enable reuse in
            the same or different environments. The FAIR principles for workflows need to be community-agreed before
            metrics can be considered to determine whether a workflow is FAIR, whether a workflow repository or registry
            is FAIR, and whether it is possible to automatically review whether a workflow’s dataflow is FAIR. Community
            activism, perhaps led by the platforms and registries coming together in a community group like <a
                href="https://workflowsri.org/" target="_blank">WorkflowsRI</a>, is needed to define principles,
            policies and best practices for FAIR workflows and to standardize metadata representation and collection
            processes.
            In this talk I will present current work on FAIR principles, practices and services for computational
            workflows, using developments in the European
            <a href="https://www.eosc-life.eu/" target="_blank">EOSC-Life</a> Workflow Collaboratory and the <a
                href="https://bioexcel.eu/" target="_blank">Bioexcel</a> Centre of Excellence.
        </p>
    </div>

    <div id="bio"
         style="background-color: #fafafa; padding: 1em 2em; margin-bottom: 1em; border-radius: 0.5em; box-shadow: #ccc 3px 3px 3px">
        <p style="line-height: 1.3em; margin-bottom: 0">
            <strong>Bio. </strong>
            <a href="https://en.wikipedia.org/wiki/Carole_Goble" target="_blank">Carole Goble</a> CBE FREng FBCS is a
            Professor of Computer Science at the University of Manchester, UK. She leads a team of Researchers, Research
            Software Engineers and Data Stewards. She has spent 25 years working in e-Science on computational
            workflows, reproducible science, open sharing, and knowledge and metadata management in a range of
            disciplines. She has led numerous e-Infrastructure projects and is currently the Head of Node of ELIXIR-UK,
            the national node of ELIXIR, the European Research Infrastructure for Life Sciences, as well as directing
            the digital infrastructure for IBISBA, the European Research Infrastructure
            for Industrial Biotechnology. Both these emphasise the use of computational workflows.
            Carole led the development of Taverna, one of the first open source computational workflow management
            systems and myExperiment.org, the first system agnostic web-based sharing platform for workflows and their
            related data. She was the scientific lead of the EU WF4Ever project which pioneered the notion of workflows
            as preservable and reproducible Research Objects. She currently co-leads developments in EOSC-Life Cluster
            Workflow Collaboratory (13 European Research Infrastructures in Biomedical Science lead by ELIXIR)
            including: the WorkflowHub.eu registry for workflows, the RO-Crate community initiative for packaging,
            exchanging and publishing workflows as Research Objects and the use of schema.org to mark up workflows. The
            tools of the Collaboratory are used by other projects from natural history collection digitisation to
            climate change modelling, and are part of the EU COVID data portal. Carole serves on the Advisory Board of
            the Common Workflow Language community and is a member of the WorkflowsRI community. In EOSC-Life she is
            leading developments on FAIR principles and practice applied to Workflows.
            Carole is also a co-founder of the UK’s Software Sustainability Institute and cares about quality research
            software and reproducibility. She is an author of the Nature paper proposing the seminal FAIR Principles for
            Scientific Data, contributes to the RDA FAIR4Research Software initiative, and actively nudges policy (OECD,
            G7, EU) to recognise software as a first class product of research.
        </p>
    </div>
    <ul style="font-size: 0.8em">
        <li style="line-height: 1.3em">
            [1] M.D. Wilkinson, M Dumontier et al, The FAIR Guiding Principles for scientific data management and
            stewardship, Scientific Data 3, (2016), DOI: <a href="https://doi.org/10.1038/sdata.2016.18"
                                                            target="_blank">10.1038/sdata.2016.18</a>
        </li>
        <li style="line-height: 1.3em">
            [2] D.S. Katz, M Gruenpeter, T Honeyman Taking a fresh look at FAIR for research software PATTERNS 2(2)
            (2021), DOI: <a href="https://doi.org/10.1016/j.patter.2021.100222" target="_blank">10.1016/j.patter.2021.100222</a>
        </li>
        <li style="line-height: 1.3em">
            [3] T Reiter, P.T Brooks, L Irber, S.E.K Joslin, C.M Reid, C Scott, C.T Brown, N.T Pierce-Ward,
            Streamlining data-intensive biology with workflow systems, GigaScience, 10(1) 2021, giaa140,
            DOI: <a href="https://doi.org/10.1093/gigascience/giaa140" target="_blank">10.1093/gigascience/giaa140</a>
        </li>
        <li style="line-height: 1.3em">
            [4] W Maier, S Bray et al Freely accessible ready to use global infrastructure for SARS-CoV-2 monitoring
            bioRxiv (2021) doi: <a href="https://doi.org/10.1101/2021.03.25.437046" target="_blank">10.1101/2021.03.25.437046</a>
        </li>
        <li style="line-height: 1.3em">
            [5] L. Wratten, A. Wilm, J Göke Reproducible, scalable, and shareable analysis pipelines with
            bioinformatics workflow managers. Nat Methods (2021). DOI: <a
                href="https://doi.org/10.1038/s41592-021-01254-9" target="_blank">10.1038/s41592-021-01254-9</a>
        </li>
        <li style="line-height: 1.3em">
            [6] C Goble, S Cohen-Boulakia, S Soiland-Reyes, D Garijo, Y Gil, M.R. Crusoe, K Peters, D Schober FAIR
            Computational Workflows Data Intelligence 2020 2:1-2, 108-121,
            DOI: <a href="https://doi.org/10.1162/dint_a_00033" target="_blank">10.1162/dint_a_00033</a>.
        </li>
        <li style="line-height: 1.3em">
            [7] S Soiland-Reyes, P Sefton, et al Packaging research artefacts with RO-Crate,
            <a href="https://arxiv.org/abs/2108.06503v1" target="_blank">arXiv:2108.06503v1</a>
        </li>
        <li style="line-height: 1.3em">
            [8] M Crusoe et al Methods Included: Standardizing Computational Reuse and Portability with the Common
            Workflow Language, CACM (2021), DOI: <a href="https://doi.org/10.1145/3486897" target="_blank">10.1145/3486897</a>
        </li>
        <li style="line-height: 1.3em">
            [9] P Andrio, A Hospital, J Conejero et al. BioExcel Building Blocks, a software library for
            interoperable biomolecular simulation workflows. Sci Data 6, 169 (2019).
            DOI: <a href="https://doi.org/10.1038/s41597-019-0177-4" target="_blank">10.1038/s41597-019-0177-4</a>
        </li>
    </ul>
</div>
